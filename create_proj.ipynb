{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Projects and Data in Slideflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have successfully created your conda environment and installed Slideflow, you can start making your first project. In this tutorial, we will create a project that will be used to test the functionality of Slideflow.\n",
    "\n",
    "Slideflow deals in **Projects** and in **Data**. \n",
    "\n",
    "This is the typical data directory structure that is recommended for working with Slideflow:\n",
    "\n",
    "- ```PROJECTS/```: directory where all projects are stored\n",
    "    - ```TEST_PROJECT/```\n",
    "        - ```annotations.csv```: annotations file (Recommend to put other annotation files into directory ```annotations/```)\n",
    "        - ```slideflow.log```: Slideflow's console output log (you can manually set the desired logging level)\n",
    "        - ```settings.json```: project settings which should be edited for each project\n",
    "        - ```datasets.json```: address book for dataset directories\n",
    "        - ```models/```: folder containing trained model folders\n",
    "        - ```eval/```: folder containing result folders from model evaluation \n",
    "        - ```script.py``` or ```notebook.ipynb```: your experiment scripts/notebook with your code (Recommend to put into directory```scripts/```)\n",
    "- ```DATA/```: the below directories can be anywhere, pointed to in ```datasets.json```, and each should contain a subdirectory specfic to each dataset.\n",
    "    - ```slides/```: slide image directory \n",
    "    - ```roi/```: region of interest CSV files generated in QuPath by ```export_rois.groovy``` script\n",
    "    - ```tiles/```: folder used to temporarily store extracted tiles prior to saving as TFRecords; typically tiles are deleted once TFRecords are created\n",
    "    - ```tfrecords/```: folder used to store TFRecords \n",
    "\n",
    "The easiest place to put the ```tiles/``` and ```tfrecords/``` directories is in the project directory since you will be extracting tiles and creating TFRecords for each project.\n",
    "\n",
    "It is recommended to use the above directory structure to keep your projects organized.  \n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Importing libraries](#import-libraries)\n",
    "    - [Note on filepaths](#note-on-structuring-filepaths-in-your-code)<br>\n",
    "2. [Create a Project](#create-a-project)\n",
    "    - [Own data, manual creation](#option-1-create-a-project-with-your-own-data-manually)<br>\n",
    "    - [Own data, sf.create_project()](#option-2-create-a-project-with-your-own-data-using-slideflows-api-sfcreate_project)<br>\n",
    "    - [Test data, extant labshare project](#option-4-create-a-test-project-by-downloading-some-test-data)<br>\n",
    "    - [Test data, download from Amazon/Box](#pre-fe)<br>\n",
    "3. [Update settings.json and datasets.json](#update-settingsjson-and-datasetsjson)<br><br>\n",
    "4. [Create a Dataset](#create-a-dataset-class-object)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always the first step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables with os package\n",
    "import os\n",
    "os.environ['SF_BACKEND'] = 'torch' # Alternative is 'tensorflow'\n",
    "os.environ['SF_SLIDE_BACKEND'] = 'cucim' # Alternative is 'libvips'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # Set which GPU(s) to use \n",
    "\n",
    "# Check if GPU is available\n",
    "if os.environ['SF_BACKEND']=='torch':\n",
    "    import torch\n",
    "    print('GPU available: ', torch.cuda.is_available())\n",
    "    print('GPU count: ', torch.cuda.device_count())\n",
    "    print('GPU current: ', torch.cuda.current_device())\n",
    "    print('GPU name: ', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "elif os.environ['SF_BACKEND']=='tensorflow':\n",
    "    import tensorflow as tf\n",
    "    print(\"GPU: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# import slideflow\n",
    "import slideflow as sf\n",
    "\n",
    "# Set verbose logging\n",
    "import logging\n",
    "logging.getLogger('slideflow').setLevel(logging.INFO)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '10'\n",
    "\n",
    "# Check if slideflow was properly installed\n",
    "sf.about()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: on structuring filepaths in your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of different servers and computers that we work on, and we have to be careful about how we structure our filepaths. You don't want to hardcode all your paths in your code, because if you have to switch your notebook from one server to another, you'll have to change all your paths.\n",
    "\n",
    "So, set your paths at the beginning of your notebook, and then use those variables throughout your code. The below is just an example, but think about structuring things this way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, for projects on Randi's scratch space (or local workstation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set root paths for making a quick test project on Randi's /scratch space just to play around with code\n",
    "username = \"skochanny\"\n",
    "project_name = \"TEST_PROJECT\"\n",
    "project_root_path = f'/scratch/{username}/PROJECTS/{project_name}'\n",
    "# labshare_path will change depending on if you are on Randi v. wheelbarrow v. workstation\n",
    "labshare_path = '/gpfs/data/pearson-lab/'\n",
    "project_root_path = os.path.join(labshare_path, project_root_path)\n",
    "# useful for specific paths to data on the labshare so you can os.join.path(labshare_path, relative_data_path) to point to where the data is\n",
    "relative_data_path = \"PROJECTS/TEST_PROJECTS/lung-adeno-v-squam\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few different options to create a project, we'll offer a few different options based on if you want to create a project with your own data vs. downloading some test data just to get you started. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Create a project with your own data manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This option is simple, and what I have done many times in the past. I use a file browser or the command line and I create all of my directories manually, then use a text editor to create & edit the necessary files. Or I copy a previous project and modify it. \n",
    "\n",
    "Look, it works, and I don't have to worry about bugs in my code. \n",
    "\n",
    "Make the directory structure as listed above in [Setting up Projects and Data in Slideflow](#setting-up-projects-and-data-in-slideflow), and then go to the last section about how to [Update the settings.json and datasets.json](#update-settingsjson-and-datasetsjson)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Create a project with your own data using Slideflow's API, *sf.create_project()*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [note](#a-note-about-how-to-structure-filepaths) about paths above, or hard code paths here. We'll assume you're setting up a project on the labshare, working from Randi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"TEST_PROJECT\"\n",
    "# labshare_path will change depending on if you are on Randi v. wheelbarrow v. workstation\n",
    "labshare_path = '/gpfs/data/pearson-lab/'\n",
    "project_root_path = f\"{labshare_path}/PROJECTS/{project_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll put the ```tiles/``` and ```tfrecords/``` directories in the project directory. \n",
    "\n",
    "Notes:\n",
    "- There is an argument ```rois```, which is broken, it wants to ROIs to be a tar.gz file instead of a directory, you need to manually edit the datasets.json file afterwards.\n",
    "- Last time I did this, the ```name``` arg for the project name didn't work and I had to manually edit that as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = sf.create_project(\n",
    "        root = project_root_path,\n",
    "        annotations = f\"{project_root_path}/annotations.csv\",\n",
    "        name = 'LUADvsLUSC', # if you already have a created datasets.json, you can put the source name here\n",
    "        slides = f\"{labshare_path}/relative/path/to/slides\",\n",
    "        # rois = os.path.join(labshare_path, relative_roi_path), # is broken, wants ROIs to be a tar.gz file instead of a directory\n",
    "        tiles = f\"{project_root_path}/tiles\",\n",
    "        tfrecords = f\"{project_root_path}/tfrecords\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"TCGA_BMI\"\n",
    "# labshare_path will change depending on if you are on Randi v. wheelbarrow v. workstation\n",
    "labshare_path = '/gpfs/data/pearson-lab/'\n",
    "project_root_path = f\"{labshare_path}/PROJECTS/{project_name}\"\n",
    "\n",
    "project = sf.create_project(\n",
    "        root = project_root_path,\n",
    "        annotations = f\"{project_root_path}/annotations.csv\",\n",
    "        name = 'LUADvsLUSC', # if you already have a created datasets.json, you can put the source name here\n",
    "        slides = f\"{labshare_path}/relative/path/to/slides\",\n",
    "        # rois = os.path.join(labshare_path, relative_roi_path), # is broken, wants ROIs to be a tar.gz file instead of a directory\n",
    "        tiles = f\"{project_root_path}/tiles\",\n",
    "        tfrecords = f\"{project_root_path}/tfrecords\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (EASIEST) Option 3: Create a test project on Randi by accessing the test project data on the labshare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll assume you just want a quick test project on Randi's scratch space to play around with Slideflow.\n",
    "\n",
    "See [note](#a-note-about-how-to-structure-filepaths) about paths above, or hard code paths here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set root paths\n",
    "username = \"skochanny\" # change me\n",
    "root_path = f'/scratch/{username}/PROJECTS'\n",
    "labshare_path = '/gpfs/data/pearson-lab/'\n",
    "project_name = \"TEST_PROJECT\"\n",
    "relative_annotation_path = 'PROJECTS/TEST_PROJECTS/lung-adeno-v-squam/annotations.csv' # do not have leading / i.e. \"/DL_OTHER...\" it messes up os.path.join\n",
    "relative_slide_path = 'PROJECTS/TEST_PROJECTS/lung-adeno-v-squam/slides'\n",
    "relative_roi_path = 'PROJECTS/TEST_PROJECTS/lung-adeno-v-squam/roi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll put the ```tiles/``` and ```tfrecords/``` directories in the project directory. \n",
    "\n",
    "Notes:\n",
    "- There is an argument ```rois```, which is broken, it wants to ROIs to be a tar.gz file instead of a directory, you need to manually edit the datasets.json file afterwards.\n",
    "- Last time I did this, the ```name``` arg for the project name didn't work and I had to manually edit that as well. \n",
    "- I used ```os.path.join()``` below but you can also use ```f\"{}\"``` to format strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new project, if one does not already exist\n",
    "project_root_path = os.path.join(root_path, project_name)\n",
    "project = sf.create_project(\n",
    "        root = project_root_path,\n",
    "        annotations = os.path.join(labshare_path, relative_annotation_path),\n",
    "        name = 'LUADvsLUSC', # if you already have a created datasets.json, you can put the source name here\n",
    "        slides = os.path.join(labshare_path, relative_slide_path),\n",
    "        # rois = os.path.join(labshare_path, relative_roi_path),\n",
    "        tiles = os.path.join(project_root_path, \"tiles\"),\n",
    "        tfrecords = os.path.join(project_root_path, \"tfrecords\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 4: Create a test project by downloading some test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UChicago Box repo option:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a project plus test data which you can download from [here](\"https://uchicago.box.com/s/02puzu0dzp9mtfej2gabe0t4d1zn2m0b\"). You will need to update the paths in ```datasets.json``` and ```settings.json``` to point to your data directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make automatic download of data from box\n",
    "dl_path=\"https://uchicago.box.com/s/02puzu0dzp9mtfej2gabe0t4d1zn2m0b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amazon S3 repo option:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three things available for download, which you can choose by specifying the ```REMOTE_DIRECTORY_NAME``` variable.\n",
    "- ```REMOTE_DIRECTORY_NAME = 'TEST_PROJECT'```: Project folder with some sample data for testing (TCGA lung)\n",
    "- ```REMOTE_DIRECTORY_NAME = 'lung-adeno-v-squam'```: TCGA lung slides, ROIs, and annotation file\n",
    "- ```REMOTE_DIRECTORY_NAME = 'thyroid-braf-v-ras'```: TCGA thyroid slides, ROIs, and annotation file\n",
    "\n",
    "You will need to update the paths in ```datasets.json``` and ```settings.json``` to point to your data directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a test project/test data from our public Amazon S3 bucket at s3://slideflow-test-projects\n",
    "import boto3\n",
    "import os \n",
    "\n",
    "def download_s3_folder(bucket_name, s3_folder, local_dir=None):\n",
    "    \"\"\"\n",
    "    Download the contents of a folder directory\n",
    "    Args:\n",
    "        bucket_name: the name of the s3 bucket\n",
    "        s3_folder: the folder path in the s3 bucket\n",
    "        local_dir: a relative or absolute directory path in the local file system\n",
    "    \"\"\"\n",
    "    s3 = boto3.resource('s3') # assumes credentials & configuration are handled outside python in .aws directory or environment variables\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    for obj in bucket.objects.filter(Prefix=s3_folder):\n",
    "        target = obj.key if local_dir is None \\\n",
    "            else os.path.join(local_dir, os.path.relpath(obj.key, s3_folder))\n",
    "        if not os.path.exists(os.path.dirname(target)):\n",
    "            os.makedirs(os.path.dirname(target))\n",
    "        if obj.key[-1] == '/':\n",
    "            continue\n",
    "        bucket.download_file(obj.key, target)\n",
    "\n",
    "BUCKET_NAME = 'slideflow-test-projects' # replace with your bucket name\n",
    "REMOTE_DIRECTORY_NAME = 'TEST_PROJECT' # Project folder with some sample data for testing\n",
    "# REMOTE_DIRECTORY_NAME = 'lung-adeno-v-squam' # TCGA lung slides, ROIs, and annotation file\n",
    "# REMOTE_DIRECTORY_NAME = 'thyroid-braf-v-ras' # TCGA thyroid slides, ROIs, and annotation file\n",
    "\n",
    "# Set local project directory.\n",
    "project_dir = \"/Users/sarakochanny/Python/slideflow-tutorials/TEST_PROJECT\"\n",
    "\n",
    "# downloadDirectoryFroms3(BUCKET_NAME, REMOTE_DIRECTORY_NAME)\n",
    "download_s3_folder(BUCKET_NAME, REMOTE_DIRECTORY_NAME, local_dir=project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If boto3 is not installed, you can install it with ```!pip install boto3```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update settings.json and datasets.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to ensure that your settings.json and datasets.json files are updated with the correct information. Slideflow's create_project function is good, but it still has some issues sometimes, and minor typos will cause you problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```settings.json```\n",
    "\n",
    "The ```settings.json``` file should be in your project folder. Everything can be relative paths (```./``` is notation for the current directory). The \"sources\" is a list of the source names listed in ```datasets.json```.\n",
    "\n",
    "Here is an example of what ```settings.json``` should looke like. \n",
    "```\n",
    "{\n",
    "    \"name\": \"TEST_PROJECT\",\n",
    "    \"annotations\": \"./annotations.csv\",\n",
    "    \"dataset_config\": \"./datasets.json\",\n",
    "    \"sources\": [\n",
    "        \"SOURCE_1\",\n",
    "        \"SOURCE_2\"\n",
    "    ],\n",
    "    \"models_dir\": \"./models\",\n",
    "    \"eval_dir\": \"./eval\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```datasets.json``` \n",
    "\n",
    "Slideflow does not require your directories to all be in one place: your slides & ROIs can be stored in one place, the tiles & TFRecords in another, the Project folders in another. Slideflow *does* need an “address book” which lists the paths to the data for each different dataset (”datasets” are called “sources”, as you will seen in ```settings.json``` later). The “address book” is the file ```datasets.json```, and its purpose is to act as the one place were all the paths to your data are logged.\n",
    "\n",
    "The easiest place to put the ```tiles/``` and ```tfrecords/``` directories is in the project directory since you will be extracting tiles and creating TFRecords for each project.\n",
    "\n",
    "Here is what ```datasets.json``` should look like. This file requires the use of \"hard paths\" to your data (not relative paths).\n",
    "\n",
    "```\n",
    "{\n",
    "  \"SOURCE_1\":\n",
    "  {\n",
    "    \"slides\": \"/directory\",\n",
    "    \"roi\": \"/directory\",\n",
    "    \"tiles\": \"/directory\",\n",
    "    \"tfrecords\": \"/directory\",\n",
    "  },\n",
    "  \"SOURCE_2\":\n",
    "  {\n",
    "    \"slides\": \"/directory\",\n",
    "    \"roi\": \"/directory\",\n",
    "    \"tiles\": \"/directory\",\n",
    "    \"tfrecords\": \"/directory\",\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "You can either add the lines to the JSON file manually or you can add a source to a project with the below code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import slideflow as sf\n",
    "P = sf.load_project('/path/to/project/directory')\n",
    "P.add_source(\n",
    "    name=\"SOURCE_NAME\",\n",
    "    slides=\"/slides/directory\",\n",
    "    roi=\"/roi/directory\",\n",
    "    tiles=\"/tiles/directory\",\n",
    "    tfrecords=\"/tfrecords/directory\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your Project has been created and your data paths have been added to the ```datasets.json``` file, you can start working with Slideflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Dataset class object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am pretty sure that you don't need to create a whole project to work with slideflow, you can just create a Dataset object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize a [Dataset object](https://slideflow.dev/dataset/), you need the following:\n",
    "- `config`: Path to the `datasets.json` file that lists data.\n",
    "- `sources`: Name of each of the datasets you want to include in the analysis. These are the names that you provided for each dataset listed in the `datasets.json` file\n",
    "- `annotations`: path to annotation file<br>\n",
    "- The `tile_px` and `tile_um` will most likely be 299 and 302, respectively, which is about 10x magnification. For feature extraction, 224px/224um is the expected tile size for most extractors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset (LUADvsLUSC) from the test project data\n",
    "dataset = sf.Dataset(\n",
    "        config='/hard/path/to/datasets.json',\n",
    "        sources=['LUADvsLUSC'],\n",
    "        annotations='/hard/path/to/annotations/annotations.csv',\n",
    "        tile_px=299,\n",
    "        tile_um=302) \n",
    "\n",
    "# Get a summary of the dataset\n",
    "dataset.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some situations, you may want to perform analysis only on a subset of images within a single dataset. You can filter a dataset by a specific feature of the annotation file with `Dataset.filter()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by site. Sites included in the filter will be included in the dataset\n",
    "# This is an example of filtering, for the purposes of this tutorial, we will not filter\n",
    "filter_dataset = dataset.filter({'site': ['Site-97', 'Site-40', 'Site-9', 'Site-177', 'Site-130', 'Side-69', 'Site-67', 'Site-93', 'Site-96']})"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
