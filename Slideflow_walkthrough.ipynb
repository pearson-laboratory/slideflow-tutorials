{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slideflow Setup Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook is meant to be your ground zero for working with Slideflow, including important information about using Linux, Bash, CUDA, plus info about other packages and commands that you will need to know to run experiments with Slideflow on your local workstation or HPC. \n",
    "\n",
    "Everything has been set up to be able to run within a Jupyter Notebook so that you can experiment with the commands. \n",
    "\n",
    "**This guide assumes that you already have installed Slideflow and created a conda environment for it.**\n",
    "\n",
    "--------\n",
    "\n",
    "Table of Contents:\n",
    "- [Import libraries, set up environment](#import-libraries-set-environment-variables-check-gpus)\n",
    "- [Setting up Projects and Data in Slideflow](#setting-up-projects-and-data-in-slideflow)\n",
    "- [Advanced section](#advanced)\n",
    "    - [Bash commands in Jupyter Notebooks](#Bash-commands-in-Jupyter-Notebooks)\n",
    "    - [Magic commands](#Magic-commands)\n",
    "    - [Importing packages and modules from different locations](#importing-packages-and-modules-from-different-locations)\n",
    "    - [CUDA help](#cuda)\n",
    "    - [System monitoring and information](#system-monitoring-and-information)\n",
    "    - [Running code in a standalone script](#running-code-in-a-standalone-script)\n",
    "    - [Multiprocessing help](#multiprocessing-help)\n",
    "    - [Datasets.json importing for filepaths](#importing-datasetsjson-to-get-data-filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries, set environment variables, check GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables with os package\n",
    "import os\n",
    "os.environ['SF_BACKEND'] = 'torch' # Alternative is 'tensorflow'\n",
    "os.environ['SF_SLIDE_BACKEND'] = 'cucim' # Alternative is 'libvips'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # Set which GPU(s) to use \n",
    "\n",
    "# Check if GPU is available\n",
    "if os.environ['SF_BACKEND']=='torch':\n",
    "    import torch\n",
    "    print('GPU available: ', torch.cuda.is_available())\n",
    "    print('GPU count: ', torch.cuda.device_count())\n",
    "    print('GPU current: ', torch.cuda.current_device())\n",
    "    print('GPU name: ', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "elif os.environ['SF_BACKEND']=='tensorflow':\n",
    "    import tensorflow as tf\n",
    "    print(\"GPU: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# import slideflow\n",
    "import slideflow as sf\n",
    "\n",
    "# Set verbose logging\n",
    "import logging\n",
    "logging.getLogger('slideflow').setLevel(logging.INFO)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '10'\n",
    "\n",
    "# Check if slideflow was properly installed\n",
    "sf.about()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first must set our environment variables. These are variables that are set in the operating system (OS) and are accessible to all programs running in that OS. You **must** set these variables *before* importing Slideflow, or Slideflow will compile to the default backend (torch.)\n",
    "- ```SF_BACKEND``` determines if Slideflow will use Pytorch ('torch') or Tensorflow ('tensorflow') as the backend for machine learning related functionality. We recommend using Pytorch as it is more intuitive and its documentation is better. \n",
    "- ```SF_SLIDE_BACKEND``` determines if Slideflow will use 'libvips' or 'cucim' as the image processing library for whole slide images. [cucim](https://github.com/rapidsai/cucim) is much faster but works with fewer file formats, [libvips](https://www.libvips.org/) is slower but adds support for *.scn, *.mrxs, *.ndpi, *.vms, and *.vmu files. We recommend cucim for its speed. \n",
    "- ```CUDA_VISIBLE_DEVICES``` determines which GPU(s) Slideflow should use for GPU-accelerated tasks and processes. Every GPU is assigned an integer ID. When working on a multi-GPU system, if you do not specify which GPU to use, a GPU already in use by another user may be chosen. Your process may try to assign GPU memory that is already in use, which won't work and could kill your process and the other user's process. You can use ```nvidia-smi``` from the command line to see which GPUs are in use (see [Advanced:CUDA](#cuda) for more).\n",
    "\n",
    "We can set our environment variables using the ```os``` module in Python. The OS module allows Python to interact with the operating system. It provides functions for creating and removing directories, fetching directory contents, identifying the current directory. The ```os.path``` module provides functions for working with system filepaths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables with os package\n",
    "import os\n",
    "os.environ['SF_BACKEND'] = 'torch' # Alternative is 'tensorflow'\n",
    "os.environ['SF_SLIDE_BACKEND'] = 'cucim' # Alternative is 'libvips'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # Set which GPU(s) to use "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, check to make sure that GPUs are available, allowing for GPU-accelerated processing. There is different code to check for GPUs depending on if you are using Pytorch or Tensorflow.\n",
    "\n",
    "FYI: GPU acceleration is enabled by the system-package CUDA, developed by NVIDIA (#1 GPU manufacturer). CUDA is a parallel computing platform and programming model that makes using a GPU for general purpose computing simple and elegant. The developer writes code as if the GPU has its own CPU, called a kernel, and the CUDA runtime and driver take care of the rest. (See [Advanced:CUDA](#cuda) for more information.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "if os.environ['SF_BACKEND']=='torch':\n",
    "    import torch\n",
    "    print('GPU available: ', torch.cuda.is_available())\n",
    "    print('GPU count: ', torch.cuda.device_count())\n",
    "    print('GPU current: ', torch.cuda.current_device())\n",
    "    print('GPU name: ', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "elif os.environ['SF_BACKEND']=='tensorflow':\n",
    "    import tensorflow as tf\n",
    "    print(\"GPU: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can import slideflow. The library slideflow is installed with pip as a software package within your conda environment. Alternatively, you can do fancier things like cloning slideflow directly from Github (see [Advanced:Importing Packages and Modules from different locations](#importing-packages-and-modules-from-different-locations) below). \n",
    "\n",
    "<!---\n",
    "Hello! This is a secret message.\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import slideflow as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logging library allows us to print messages to the console. This is useful for debugging and for keeping track of what is happening in the program. We want the most information about what is happening so we set the environment variable ```TF_CPP_MIN_LOG_LEVEL``` to ```'10'```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set verbose logging\n",
    "import logging\n",
    "logging.getLogger('slideflow').setLevel(logging.INFO)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to make sure that Slideflow was properly imported (if it wasn't, this command won't work), what version you are using, and what your backends are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.about()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Projects and Data in Slideflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have successfully created your conda environment and installed Slideflow, you can start making your first project. In this tutorial, we will create a project that will be used to test the functionality of Slideflow.\n",
    "\n",
    "Slideflow deals in **Projects** and in **Data**. \n",
    "\n",
    "This is the typical data directory structure that is recommended for working with Slideflow:\n",
    "\n",
    "- ```PROJECTS/```: directory where all projects are stored\n",
    "    - ```TEST_PROJECT/```\n",
    "        - ```annotations.csv```: annotations file (Recommend to put other annotation files into directory ```annotations/```)\n",
    "        - ```slideflow.log```: Slideflow's console output log (you can manually set the desired logging level)\n",
    "        - ```settings.json```: project settings which should be edited for each project\n",
    "        - ```datasets.json```: address book for dataset directories\n",
    "        - ```models/```: folder containing trained model folders\n",
    "        - ```eval/```: folder containing result folders from model evaluation \n",
    "        - ```script.py``` or ```notebook.ipynb```: your experiment scripts/notebook with your code (Recommend to put into directory```scripts/```)\n",
    "- ```DATA/```: the below directories can be anywhere, pointed to in ```datasets.json```, and each should contain a subdirectory specfic to each dataset.\n",
    "    - ```slides/```: slide image directory \n",
    "    - ```roi/```: region of interest CSV files generated in QuPath by ```export_rois.groovy``` script\n",
    "    - ```tiles/```: folder used to temporarily store extracted tiles prior to saving as TFRecords; typically tiles are deleted once TFRecords are created\n",
    "    - ```tfrecords/```: folder used to store TFRecords \n",
    "\n",
    "The easiest place to put the ```tiles/``` and ```tfrecords/``` directories is in the project directory since you will be extracting tiles and creating TFRecords for each project.\n",
    "\n",
    "It is recommended to use the above directory structure to keep your projects organized.  \n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download a test project and data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a project plus test data which you can download from [here](\"https://uchicago.box.com/s/02puzu0dzp9mtfej2gabe0t4d1zn2m0b\"). You will need to update the paths in ```datasets.json``` and ```settings.json``` to point to your data directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "dl_path=\"https://uchicago.box.com/s/02puzu0dzp9mtfej2gabe0t4d1zn2m0b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a project with Slideflow's API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can create a project programatically using Slideflow's API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import slideflow as sf\n",
    "P = sf.create_project(\n",
    "    root='project_path',\n",
    "    annotations=\"./annotations.csv\",\n",
    "    slides='/path/to/slides/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update settings.json and datasets.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```settings.json```\n",
    "\n",
    "The ```settings.json``` file should be in your project folder. Everything can be relative paths (```./``` is notation for the current directory) but ```datasets.json``` should be a hard path. The \"sources\" is a list of the source names listed in ```datasets.json```.\n",
    "\n",
    "Here is an example of what ```settings.json``` should looke like. \n",
    "```\n",
    "{\n",
    "    \"name\": \"TEST_PROJECT\",\n",
    "    \"annotations\": \"./annotations.csv\",\n",
    "    \"dataset_config\": \"/home/user/DATA/datasets.json\",\n",
    "    \"sources\": [\n",
    "        \"SOURCE_1\",\n",
    "        \"SOURCE_2\"\n",
    "    ],\n",
    "    \"models_dir\": \"./models\",\n",
    "    \"eval_dir\": \"./eval\",\n",
    "    \"mixed_precision\": false,\n",
    "    \"batch_train_config\": \"./sweep.json\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```datasets.json``` \n",
    "\n",
    "Slideflow does not require your directories to all be in one place: your slides & ROIs can be stored in one place, the tiles & TFRecords in another, the Project folders in another. Slideflow *does* need an ‚Äúaddress book‚Äù which lists the paths to the data for each different dataset (‚Äùdatasets‚Äù are called ‚Äúsources‚Äù, as you will seen in ```settings.json``` later). The ‚Äúaddress book‚Äù is the file ```datasets.json```, and its purpose is to act as the one place were all the paths to your data are logged.\n",
    "\n",
    "Here is what ```datasets.json``` should look like. This file requires the use of \"hard paths\" to your data (not relative paths).\n",
    "\n",
    "```\n",
    "{\n",
    "  \"SOURCE_1\":\n",
    "  {\n",
    "    \"slides\": \"/directory\",\n",
    "    \"roi\": \"/directory\",\n",
    "    \"tiles\": \"/directory\",\n",
    "    \"tfrecords\": \"/directory\",\n",
    "  },\n",
    "  \"SOURCE_2\":\n",
    "  {\n",
    "    \"slides\": \"/directory\",\n",
    "    \"roi\": \"/directory\",\n",
    "    \"tiles\": \"/directory\",\n",
    "    \"tfrecords\": \"/directory\",\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "You can either add the lines to the JSON file manually or you can add a source to a project with the below code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import slideflow as sf\n",
    "P = sf.load_project('/path/to/project/directory')\n",
    "P.add_source(\n",
    "    name=\"SOURCE_NAME\",\n",
    "    slides=\"/slides/directory\",\n",
    "    roi=\"/roi/directory\",\n",
    "    tiles=\"/tiles/directory\",\n",
    "    tfrecords=\"/tfrecords/directory\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your Project has been created and your data paths have been added to the ```datasets.json``` file, you can start working with Slideflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is everything that I think you need to understand to perform computational work on our servers. I've included some extra information that I think is useful to know, but not necessary to know.\n",
    "\n",
    "Table of Contents:\n",
    "- [Bash commands in Jupyter Notebooks](#Bash-commands-in-Jupyter-Notebooks)\n",
    "- [Magic commands](#Magic-commands)\n",
    "- [Importing packages and modules from different locations](#importing-packages-and-modules-from-different-locations)\n",
    "- [CUDA help](#cuda)\n",
    "- [System monitoring and information](#system-monitoring-and-information)\n",
    "- [Running code in a standalone script](#running-code-in-a-standalone-script)\n",
    "- [Multiprocessing help](#multiprocessing-help)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bash commands in Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To execute bash or other shell commands in a Jupyter Notebook, you should use the prefix ```!``` before the command you wish to run**. It can be really convenient to run bash commands directly within Jupyter Notebooks. \n",
    "\n",
    "Some equivalent ways to execute bash commands in Jupyter Notebooks/VSCode:\n",
    "- Use Python package equivalents (like from the ```os``` or ```sys``` libraries) \n",
    "- Execute the equivalent bash commands directly from the Terminal in VSCode\n",
    "- Use the line magic ```%``` for single-line commands or the cell magic ```%%bash``` for multi-line bash scripts (see ```Magic commands``` section below). Not every bash command will work with the line magic ```%```, but many will."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running bash scripts in Jupyter Notebooks**\n",
    "\n",
    "You can use the magic command %%bash to run a bash script in a Jupyter Notebook cell. ```$varname``` is how you call a variable in bash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Define directory and file names\n",
    "dir_name=\"example_dir\"\n",
    "file_name=\"example_file.txt\"\n",
    "\n",
    "# Create a new directory\n",
    "echo \"Creating a directory named $dir_name\"\n",
    "mkdir -p $dir_name\n",
    "\n",
    "# Navigate into the directory\n",
    "cd $dir_name\n",
    "echo \"Current working directory:\"\n",
    "pwd\n",
    "\n",
    "# Create a new file and write some content to it\n",
    "echo \"Writing to $file_name\"\n",
    "echo \"Hello, this is a test file.\" > $file_name\n",
    "\n",
    "# Display the contents of the file\n",
    "echo \"Displaying contents of $file_name:\"\n",
    "cat $file_name\n",
    "\n",
    "# Remove the file\n",
    "echo \"Removing $file_name\"\n",
    "rm $file_name\n",
    "\n",
    "# Navigate back to the original directory and delete the new directory\n",
    "cd ..\n",
    "echo \"Removing $dir_name\"\n",
    "rm -r $dir_name\n",
    "echo \"Current working directory:\"\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Bash commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple bash commands for working with files and directories: \n",
    "\n",
    "- ```ls```: Lists the contents of a directory. ```ls -l```: Provides detailed list including file permissions, number of links, owner, group, size, and modification date. ```ls -a```: Lists all files, including hidden files.\n",
    "- ```cd /path/to/directory```: Changes to the specified directory. ```cd ..```: Moves one directory up. ```cd ~```: Moves to the home directory.\n",
    "- ```pwd```: Prints the working directory. Useful to double-check what directory you are in.\n",
    "- ```mkdir <new_directory_name>```: Creates a new directory.\n",
    "- ```rm <filename>```: Remove file **permanently**. ```rm -r <directory_name>```: Recursively removes a directory and its contents **permanently** (**for the love of God, be careful with this command. Executing ```rm -r /``` will delete everything on your computer**).\n",
    "- ```touch <filename>```: Creates a new empty file or updates the timestamp of an existing file (this second function is useful if there is some sort of \"unused file deletion time limit\" set, like on certain HPC scratch spaces).\n",
    "- ```cp <file_source> <file_destination>```: Copies files and directories. ```cp -r <source_directory> <destination_directory>```: Recursively copies a directory.\n",
    "- ```mv <file_source> <file_destination>```: Moves files and directories. Also can be used to rename a file or directory (```mv <old_name> <new_name>```).\n",
    "- ```cat <file_name>```: Displays the content of a file.\n",
    "- ```grep \"pattern\" <file_name>```: Searches for a pattern in a file.\n",
    "- ```find /path/to/search -name \"file_pattern\"```: Searches for files in a directory hierarchy and finds files matching the given pattern.\n",
    "- ```echo <text_string>```: Displays a line of text/string that is passed as an argument (e.g. ```echo \"Hello World\"```: Prints \"Hello World\".) Equivalent to Python ```print()```. Useful for status updates in bash scripts. ```echo``` is also useful for printing the value of environment variables (e.g. ```echo $CUDA_VISIBLE_DEVICES```).\n",
    "- ```head <file_name>```: Shows the first 10 lines of a file.\n",
    "- ```tail <file_name>```: Shows the last 10 lines of a file.\n",
    "- ```wc -l```: Counts the newline characters in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test them out here\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can install pip packages directly from within Jupyter Notebook. (Commented out so it doesn't install if you don't want it to.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [Advanced:System monitoring and information](#system-monitoring-and-information) for other useful software programs you can run from the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magic commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magic commands are special commands that are designed to perform some common tasks you may want to do from within a Jupyter Notebook.  They are not part of the Python language, but are instead provided by the IPython Kernel (the IPython Kernel is the computational engine that executes the code in a Jupyter Notebook). \n",
    "\n",
    "Magic commands begin with either ```%``` or ```%%```. ```%``` is for single-line magics and ```%%``` is for cell magics. \n",
    "\n",
    "You can see a detailed description of all commands by running the command ```%magic```, or just a list of them with ```%lsmagic```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of them, but this is a list of some of the most useful ones:\n",
    "\n",
    "- ```%time```: Times the execution of a single statement\n",
    "- ```%pwd```: Prints the working directory path\n",
    "- ```%cd /path/to/dir```: Changes the working directory\n",
    "- ```%ls```: Lists the contents of the working directory\n",
    "- ```%run <filename>```: Executes a Python script inside a cell\n",
    "- ```%%writefile <filename>```: Writes the contents of a cell to a file\n",
    "- ```%pycat <filename>```: Shows the content of an external file and highlights the syntax (```%cat``` just prints the contents of the file)\n",
    "- ```%debug```: Drops you into the built-in Python debugger (pdb) when encountering an error. It allows for interactive debugging and variable inspection.\n",
    "- ```%env```: Lists all environment variables \n",
    "- ```%env <variable>=<value>```: Sets the environment variable <variable> to <value> (alternative to using ```os.environ['VARIABLE'] = 'VALUE'``` or bash's ```export VARIABLE=VALUE```)\n",
    "- ```%who```: Display variables that exist in the global scope (```%whos``` provides more detailed information) \n",
    "- ```%reset```: Reset the namespace by removing all variables and their values from memory\n",
    "- ```%%html```: Renders the cell as HTML\n",
    "- ```%matplotlib inline```: Displays matplotlib plots inline instead of a new window\n",
    "- ```%%bash```: Execute a multi-line bash script within the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test them out here\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are doing development work actively and wish to test your changes live in a Jupyter Notebook, you can use the magic command ```%load_ext autoreload``` to automatically reload the module every time you make a change to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages and modules from different locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why this is useful**\n",
    "\n",
    "This section useful if you want to do fancy things like work with an experimental branch of Slideflow, have a Slideflow directory that you are actively doing development on, or just keep multiple versions of Slideflow. You can use git to clone the repository directly ```git clone https://github.com/jamesdolezal/slideflow.git```, and then insert the path to the cloned repo into Python's package search path.  \n",
    "\n",
    "You can use the below methods to import any package or module from any location on your computer.\n",
    "\n",
    "------\n",
    "\n",
    "Python uses a system of modules and packages to organize code. A module is a single file (e.g. ```slideflow.py```) while a package is a collection of modules (e.g. ```slideflow/```), often organized as subdirectory folders within the main package directory. Packages can get pretty complicated, with module files within subdirectories within subdirectories. \n",
    "\n",
    "When you import a module or package, Python searches for it in an **ordered** list of directories that are stored in the ```sys.path``` variable (```sys``` manages system-specific parameters and functions). You can see the directories in ```sys.path``` using ```print(sys.path)```. \n",
    "\n",
    "```\n",
    "import sys\n",
    "print(sys.path)\n",
    "\n",
    "['/home/pearsonlab/PROJECTS/TEST_PROJECT',\n",
    " '/home/pearsonlab/anaconda3/envs/sf/lib/python38.zip',\n",
    " '/home/pearsonlab/anaconda3/envs/sf/lib/python3.8',\n",
    " '/home/pearsonlab/anaconda3/envs/sf/lib/python3.8/lib-dynload',\n",
    " '/home/pearsonlab/.local/lib/python3.8/site-packages',\n",
    " '/home/pearsonlab/anaconda3/envs/sf/lib/python3.8/site-packages']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Python will search for modules and packages in the current working directory (the directory you are in when you start Python, in this example ```/home/pearsonlab/PROJECTS/TEST_PROJECT```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd() # you can also use %pwd or !pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to import a module or package from a different directory, you can add that directory to ```sys.path```. \n",
    "\n",
    "So for example, if you have a specific slideflow directory (perhaps from a specific branch or with local changes you've made) you want to work from, you can set the path to that slideflow directory and slideflow will be imported from there instead. \n",
    "\n",
    "```\n",
    "import sys\n",
    "sf_path = \"/home/pearsonlab/sf_dev/\"\n",
    "sys.path.insert(0, sf_path)\n",
    "import slideflow as sf\n",
    "print(sys.path)\n",
    "\n",
    "['/home/pearsonlab/sf_dev/',\n",
    " '/home/pearsonlab/PROJECTS/TEST_PROJECT',\n",
    " '/home/pearsonlab/anaconda3/envs/sf/lib/python38.zip',\n",
    " '/home/pearsonlab/anaconda3/envs/sf/lib/python3.8',\n",
    " '/home/pearsonlab/anaconda3/envs/sf/lib/python3.8/lib-dynload',\n",
    " '/home/pearsonlab/.local/lib/python3.8/site-packages',\n",
    " '/home/pearsonlab/anaconda3/envs/sf/lib/python3.8/site-packages']\n",
    "```\n",
    "\n",
    "As you can see, the path to ```sf_dev``` was inserted first, so Slideflow is imported from the directory ```sf_dev``` instead of the directory where you are currently working (```/home/pearsonlab/PROJECTS/TEST_PROJECT```), or the conda env directory (```/home/pearsonlab/anaconda3/envs/sf/lib```) where slideflow is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing files and modules \n",
    "# from other locations\n",
    "import sys\n",
    "sf_path = \"/home/pearsonlab/sf/\" \n",
    "sys.path.insert(0, sf_path)\n",
    "import slideflow as sf                                                          # type: ignore\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE 1: The above steps work for importing modules (single Python ```.py``` files) as well.**\n",
    "\n",
    "Let's say that you have a standalone Python file that contains a bunch of functions and classes you have written yourself. You want to import those functions and classes into your Jupyter Notebook or standalone Python script. To do this, you follow the very same steps as above, but instead of importing a package, you are importing a module. \n",
    "\n",
    "```\n",
    "import sys\n",
    "module_dir_path = \"/path/to/dir/with/my/python/file/\"\n",
    "sys.path.insert(0, module_dir_path)\n",
    "import module\n",
    "```\n",
    "\n",
    "This will import all of the functions and classes from ```module.py``` into your Jupyter Notebook. I also sometimes use ```from module import *``` which can be easier because then I don't have to write the module name (like in ```module.function()```) each time I want to use a function from the module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE 2: If you are doing development work actively and wish to test your changes live in a Jupyter Notebook, you can use the magic command ```%load_ext autoreload``` to automatically reload the module every time you make a change to it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why this section is useful**\n",
    "\n",
    "This section is useful so you understand how CUDA works. It must be installed by a system admin with sudo privileges, and sometimes it can be a pain to get it working if your paths are not set up properly. You want to be able to check that it is installed, part of your system PATH, visible by your deep learning library (Pytorch or Tensorflow), and working properly. Useful commands are also included.\n",
    "\n",
    "--------\n",
    "\n",
    "CUDA (Compute Unified Device Architecture) is a specialized programming approach for instructing NVIDIA GPUs. When you train a neural network, each layer's operations, such as convolutions and matrix multiplications, can be computed in parallel on a GPU. CUDA provides the necessary tools and language extensions (in C/C++) to developers to write programs that harness this parallelism. You will not interact with the CUDA libraries directly, but you'll interface with CUDA via Tensorflow or Pytorch. \n",
    "\n",
    "Before using these commands and functions, you must have the necessary NVIDIA drivers, CUDA Toolkit, and appropriate Python libraries installed. Your system admins (James or Sara) have ensured that CUDA is installed on the Pearson Lab servers (this requires sudo privileges) BUT you need to make sure that its install location is part of your PATH variable (where the OS looks for programs to run). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking that CUDA is installed\n",
    "\n",
    "There are a few options how to check if CUDA is installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: nvcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the CUDA version with the command ```nvcc --version```. This will print the version of the CUDA compiler driver. If this command doesn't work, then either CUDA isn't installed, or its install location isn't part of your PATH variable (see below).\n",
    "\n",
    "Sometimes, the ```nvcc``` command won't work because the path to the CUDA library isn't specified in your path. You can also execute the command by specifying the full path to the nvcc executable. For example, on the Pearson Lab servers, the full path is ```/usr/local/cuda/bin/nvcc```. This is true of almost any command that you want to run from the command line. If you don't know the full path, you can use the ```which``` command to find it. For example, ```which nvcc``` returns ```/usr/local/cuda/bin/nvcc```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Use torch or tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SF_BACKEND'] = 'torch' # Alternative is 'tensorflow'\n",
    "\n",
    "# Check if GPU is available - Does not work on Macs\n",
    "if os.environ['SF_BACKEND']=='torch':\n",
    "    import torch\n",
    "    print('GPU available: ', torch.cuda.is_available())\n",
    "    print('GPU count: ', torch.cuda.device_count())\n",
    "    print('GPU current: ', torch.cuda.current_device())\n",
    "    print('GPU name: ', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "elif os.environ['SF_BACKEND']=='tensorflow':\n",
    "    import tensorflow as tf\n",
    "    print(\"GPU: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking CUDA's path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commands like ```export PATH=/usr/local/cuda/bin:$PATH``` and ```export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH``` set the paths to the proper CUDA libraries and software. They should be in your ```~/.bashrc``` file so that they are set every time you log in (they should be before the Conda initialization section).\n",
    "\n",
    "You can check the path to the CUDA library with the command ```echo $PATH``` or ```echo $LD_LIBRARY_PATH```. This will print the path to the CUDA libraries (should be in ```/usr/local```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking CUDA's path\n",
    "!echo $PATH\n",
    "!echo $LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful CUDA commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```nvidia-smi```: Displays information about NVIDIA GPU(s) on your system, including usage, temperature, memory, and driver version. It's a go-to command for monitoring GPU health and activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```nvcc --version``` or ```nvcc -V```: Shows the version of the NVIDIA CUDA Compiler (NVCC). Useful for checking your CUDA toolkit version. This won't work if your CUDA path is messed up (see [Checking that CUDA is installed](#checking-that-cuda-is-installed) for more)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```export CUDA_VISIBLE_DEVICES=0,1```: This command sets the environment variable to specify which GPUs should be accessible to CUDA applications.\n",
    "\n",
    "The environment variable ```CUDA_VISIBLE_DEVICES``` determines which GPU(s) Slideflow should use for GPU-accelerated tasks and processes. Every GPU is assigned an integer ID. When working on a multi-GPU system, if you do not specify which GPU to use, a GPU already in use by another user may be chosen. Your process may try to assign GPU memory that is already in use, which won't work and could kill your process and the other user's process. You can use ```nvidia-smi``` from the command line to see which GPUs are in use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0,1\n",
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System monitoring and information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to be able to monitor your processes and what is going on with them. You may also want to be able to monitor the system as a whole. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tmux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tmux](https://github.com/tmux/tmux/wiki) is an open-source terminal multiplexer for Unix-based operating systems. It allows users to create multiple windows and panes within the same terminal. This is useful for running multiple programs with a single connection, such as when you're remotely connecting to a machine using Secure Shell (SSH). **Most importantly, ```tmux``` allows you to detach from a session and reattach later, which is useful if you have a long-running process that you want to keep running even if you disconnect from the server.**\n",
    "\n",
    "**You must run tmux in the Terminal/Command Line.** \n",
    "\n",
    "```tmux``` relies on using keyboard shortcuts (i.e. ```Ctrl+b + 0```) to control the session and navigate between windows and panes. You can also use ```Shift+:``` to input commands.  You can see a full list of keyboard shortcuts and commands [here](https://tmuxcheatsheet.com/).\n",
    "\n",
    "Some useful commands:\n",
    "1. ```tmux new -s <session_name>```: Creates a new tmux session with the name <session_name>.\n",
    "2. ```tmux a -t mysession```: Reattach to previously created session named \"mysession\".\n",
    "3. ```tmux kill-session -t mysession```: Kill the current session.\n",
    "4. ```Ctrl+b + d```: A keyboard shortcut within tmux. Detach from tmux session.\n",
    "5. ```: split-window -v```: Input command within tmux. Splits the current pane vertically (-h for horizontal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tmux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glances ([website](https://nicolargo.github.io/glances/)) is a cross-platform system monitoring tool written in Python. It monitors & shows usage for CPU, GPU, RAM, network, disk I/O, disk usage, IP address, and more. It's fantastic. \n",
    "\n",
    "It also has a web interface so that you can monitor your system from a web browser.\n",
    "\n",
    "**NOTE: Glances looks utterly terrible in a Jupyter Notebook. Use a terminal window.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!glances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below for an example image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<img src=\"https://nicolargo.github.io/glances/public/images/screenshot-wide.png\" style=\"height:500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inxi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```inxi``` ([docs](https://smxi.org/docs/inxi.htm)) is an *extraordinarily* useful tool if you want to get information about hardware specifications or OS/kernel versions.  \n",
    "\n",
    "The command ```inxi``` shows system hardware information based on the flag (```-b``` is basic info, ```-F``` is full output). Specific outputs: CPU (```-C```), graphics (```-G```), hard disks (```-D```), RAM (```-m```), IP address (```-i```), network (```-n```), general info (```-I```), and much more (```-h``` for full list of options).\n",
    "\n",
    "It is not installed on Linux machines by default (your sys admin should do this). Available on Homebrew for Macs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic info\n",
    "!inxi -b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ncdu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The typical bash command for checking disk usage is ```du```, but it's not very pretty or human readable. ```ncdu``` (NCurses Disk Usage) ([docs](https://dev.yorhel.nl/ncdu)) on the other hand is fantastic and easy to use. It lets you use the arrow keys to navigate the directory tree and see disk usage for each directory. You can delete files and directories from within the program. It may need to be installed by your sys admin if it isn't already.\n",
    "\n",
    "Run the below cell for example image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://ostechnix.com/wp-content/uploads/2022/08/Check-Disk-Space-Usage-With-Ncdu.png\" style=\"height:400px\">\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<img src=\"https://ostechnix.com/wp-content/uploads/2022/08/Check-Disk-Space-Usage-With-Ncdu.png\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ntfy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A phone app that sends you a notification when a command finishes running. Useful for long-running processes.\n",
    "\n",
    "Steps: \n",
    "1. Download ntfy [here](https://ntfy.sh/) to your desired device.\n",
    "2. Create a unique name for your \"topic\" (i.e. the experiment name), which generates a unique URL.\n",
    "3. Add the below (example) code within your Python script, which will post a message to your topic.\n",
    "4. You get a notification on your phone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first argument is the unique topic URL, data is the message to send\n",
    "import requests\n",
    "requests.post(\"https://ntfy.sh/mytopic\", data=\"Backup successful üòÄ\".encode(encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running code in standalone script\n",
    "\n",
    "The advantage of NOT using a Jupyter Notebook comes from escaping the constraints that come with running things within Jupyter Notebooks. For example, you can't run code in parallel within a Jupyter Notebook. You can only run code sequentially. This is because Jupyter Notebooks are designed to be interactive, and parallel processing is not interactive.\n",
    "\n",
    "Instead, you can run code in a standalone Python script (i.e. ```experiment.py```) and then execute this script with python from the command line: ```python3 experiment.py``` (use the full path if needed).\n",
    "\n",
    "Ideally, you should execute scripts on the command line from within a [TMUX](#tmux) session to ensure that long-running processes are not interrupted due to lost of connection to your remote server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile experiment.py\n",
    "# use the above line to write the contents of this cell to a file and then execute it\n",
    "\n",
    "# test script\n",
    "print(\"hello world\")\n",
    "\n",
    "# import libraries\n",
    "import os\n",
    "import slideflow as sf\n",
    "\n",
    "# Check if slideflow was properly installed\n",
    "sf.about()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the file (which should be done on the command line, ideally in a TMUX session)\n",
    "!python3 experiment.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the file\n",
    "%rm experiment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why this section is useful**\n",
    "\n",
    "Multiprocessing in Python is a means to perform parallel processing by using multiple processors on a machine (as opposed to sequential/serial processing). This is particularly useful for CPU-bound tasks that can be parallelized. \n",
    "\n",
    "A *program* (like Python) is static: it is the data and information itself that needs to be processed and executed, while a *process* is when the actual program is in memory and under the control of the CPU.\n",
    "\n",
    "The library ```multiprocessing``` allows for executed \"parent\" processes to be divided into \"child\" processes which are executed in parallel (instead of all processes runnning sequentially). Each child process is assigned its own memory (RAM) and CPU *thread* (a thread is the virtual sequence of instructions given to a CPU). This massively speeds up processing time but also requires higher memory overheads, because each child process requires it's own memory (so memory is duplicated in an additive manner). So beware that what you trade for faster speeds, you lose in memory usage.\n",
    "\n",
    "Threads run within some process. A process can have more than one thread and each thread **shares** the memory and resources of the process (which means they can access shared data). Multithreading (versus multiprocessing) is how you can speed up computation but avoid the higher memory overheads. For example, Slideflow's ```extract_tiles()``` utilizes multithreading to speed up tile extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO examples coming soon!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing datasets.json to get data filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To organize our projects, we utilize a JSON directory file called ‚Äúdatasets.json‚Äù that lists the name of the dataset and the paths to the desired data. Slideflow has built-in functionality to utilize this file, but it is simple enough to load in the JSON file as a Python dictionary and access your paths from there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first five datasets:\n",
      "{'TCGA_ACC_NORM': {'roi': '/mnt/labshare/SLIDES/TCGA-ACC/ROI',\n",
      "                   'slides': '/mnt/labshare/SLIDES/TCGA-ACC/images',\n",
      "                   'tfrecords': '/mnt/data/TFRECORDS/NORMAL/TCGA_ACC_NORM',\n",
      "                   'tiles': '/mnt/data/TILES/NORMAL/TCGA_ACC_NORM'},\n",
      " 'UCH_BRCA_ADJUVANT': {'roi': '',\n",
      "                       'slides': '/auto/pearson-lab/SLIDES/UCH_BRCA_ADJUVANT/',\n",
      "                       'tfrecords': '/mnt/data/TFRECORDS/TUMOR/UCH_BRCA_ADJUVANT',\n",
      "                       'tiles': '/mnt/data/TILES/TUMOR/UCH_BRCA_ADJUVANT'},\n",
      " 'UCH_BRCA_HER2': {'roi': '',\n",
      "                   'slides': '/auto/pearson-lab/SLIDES/UCH_BRCA_HER2/',\n",
      "                   'tfrecords': '/mnt/data/TFRECORDS/TUMOR/UCH_BRCA_HER2',\n",
      "                   'tiles': '/mnt/data/TILES/TUMOR/UCH_BRCA_HER2'},\n",
      " 'UCH_BRCA_NAC': {'roi': '/auto/pearson-lab/QUPATH/UCH_BRCA_NAC/ROI/',\n",
      "                  'slides': '/auto/pearson-lab/SLIDES/UCH_BRCA_NAC/images/',\n",
      "                  'tfrecords': '/mnt/data/TFRECORDS/TUMOR/UCH_BRCA_NAC',\n",
      "                  'tiles': '/mnt/data/TILES/TUMOR/UCH_BRCA_NAC'},\n",
      " 'UCH_BRCA_RS': {'roi': '/mnt/labshare/SLIDES/UCH_BRCA_RS/AT/',\n",
      "                 'slides': '/auto/pearson-lab/QUPATH/UCH_BRCA_RS/images',\n",
      "                 'tfrecords': '/mnt/data/TFRECORDS/TUMOR/UCH_BRCA_RS',\n",
      "                 'tiles': '/mnt/data/TILES/TUMOR/UCH_BRCA_RS'}}\n",
      "The slides path for UCH_BRCA_ADJUVANT is: /auto/pearson-lab/SLIDES/UCH_BRCA_ADJUVANT/\n"
     ]
    }
   ],
   "source": [
    "datasets_path = \"/Users/sarakochanny/Python/datasets.json\"\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Open the JSON file\n",
    "with open(datasets_path) as json_file:\n",
    "    # Load the JSON data into a Python dictionary\n",
    "    datasets = json.load(json_file)\n",
    "\n",
    "# Get the path for \n",
    "print(\"The first five datasets:\")\n",
    "pprint(dict(list(datasets.items())[:5]))\n",
    "\n",
    "# You can set the slides path for your data using this, say for 'UCH_BRCA_ADJUVANT'\n",
    "slides_path = datasets['UCH_BRCA_ADJUVANT']['slides']\n",
    "print(\"The slides path for UCH_BRCA_ADJUVANT is:\", slides_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
