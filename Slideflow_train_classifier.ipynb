{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluating classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: You cannot take advantage of parallel processing with GPUs from within a Jupyter notebook so tasks requiring or benefitting from multiple GPUs should use .py scripts instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always the first step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables with os package\n",
    "import os\n",
    "os.environ['SF_BACKEND'] = 'torch' # Alternative is 'tensorflow'\n",
    "os.environ['SF_SLIDE_BACKEND'] = 'cucim' # Alternative is 'libvips'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # Set which GPU(s) to use \n",
    "\n",
    "# Check if GPU is available\n",
    "if os.environ['SF_BACKEND']=='torch':\n",
    "    import torch\n",
    "    print('GPU available: ', torch.cuda.is_available())\n",
    "    print('GPU count: ', torch.cuda.device_count())\n",
    "    print('GPU current: ', torch.cuda.current_device())\n",
    "    print('GPU name: ', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "elif os.environ['SF_BACKEND']=='tensorflow':\n",
    "    import tensorflow as tf\n",
    "    print(\"GPU: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# import slideflow\n",
    "import slideflow as sf\n",
    "from slideflow import simclr\n",
    "from slideflow.slide import qc\n",
    "\n",
    "# Set verbose logging\n",
    "import logging\n",
    "logging.getLogger('slideflow').setLevel(logging.INFO)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '10'\n",
    "import sys\n",
    "sys.stderr = sys.__stdout__\n",
    "\n",
    "# Check if slideflow was properly installed\n",
    "sf.about()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick and easy project setup on Randi\n",
    "\n",
    "# # Set root paths\n",
    "# username = \"skochanny\" # change me\n",
    "# root_path = f'/scratch/{username}/PROJECTS'\n",
    "# labshare_path = '/gpfs/data/pearson-lab/'\n",
    "# project_name = \"TEST_PROJECT\"\n",
    "# relative_annotation_path = 'DL_OTHER/TEST_PROJECTS/lung-adeno-v-squam/annotations.csv' # do not have leading / i.e. \"/DL_OTHER...\" it messes up os.path.join\n",
    "# relative_slide_path = 'DL_OTHER/TEST_PROJECTS/lung-adeno-v-squam/slides'\n",
    "# relative_roi_path = 'DL_OTHER/TEST_PROJECTS/lung-adeno-v-squam/roi'\n",
    "\n",
    "# # Create a new project, if one does not already exist\n",
    "# project_root_path = os.path.join(root_path, project_name)\n",
    "# project = sf.create_project(\n",
    "#         root = project_root_path,\n",
    "#         annotations = os.path.join(labshare_path, relative_annotation_path),\n",
    "#         name = 'LUADvsLUSC', # if you already have a created datasets.json, you can put the source name here\n",
    "#         slides = os.path.join(labshare_path, relative_slide_path),\n",
    "#         # rois = os.path.join(labshare_path, relative_roi_path),\n",
    "#         tiles = os.path.join(project_root_path, \"tiles\"),\n",
    "#         tfrecords = os.path.join(project_root_path, \"tfrecords\")\n",
    "#     )\n",
    "\n",
    "# # Notes:\n",
    "# # - There is an argument ```rois```, which is broken, it wants to ROIs to be a tar.gz file instead of a directory, you need to manually edit the datasets.json file afterwards.\n",
    "# # - Last time I did this, the ```name``` arg for the project name didn't work and I had to manually edit that as well. \n",
    "# # - I used ```os.path.join()``` below but you can also use ```f\"{}\"``` to format strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='import'></a>\n",
    "### Getting Started with a Slideflow Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are starting this tutorial under the assumption that you have already initialized a slideflow project. Once the project has been created and you have specified the paths to datasets, annotation files, etc. we will begin by initializing a Slideflow Project object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set root paths\n",
    "username = \"skochanny\"\n",
    "root_path = f'/scratch/{username}/PROJECTS'\n",
    "labshare_path = '/gpfs/data/pearson-lab/'\n",
    "project_name = \"TEST_PROJECT\"\n",
    "project_root_path = f\"{root_path}/{project_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the Project class object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be sure to check that the project path is correct\n",
    "P = sf.Project(project_root_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Training with a Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have your Project set up already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import libraries & set vars\n",
    "import os\n",
    "import slideflow as sf\n",
    "os.environ['SF_BACKEND'] = 'torch'\n",
    "\n",
    "# 2. initialize project\n",
    "project_root = '/home/pearsonlab/DATA/PROJECTS/TEST_PROJECT'\n",
    "P = sf.Project(root=project_root)\n",
    "\n",
    "# 3. set hyperparameters\n",
    "hp = sf.ModelParams(\n",
    "    tile_px=299, \n",
    "    tile_um=302, \n",
    "    epochs=[5], # will save a model and results after each epoch in the list (i.e. [1,3,5]) \n",
    "    toplayer_epochs=0, \n",
    "    model='xception', \n",
    "    pooling='avg',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    learning_rate=0.0001, \n",
    "    learning_rate_decay=0.98,\n",
    "    learning_rate_decay_steps=512, \n",
    "    batch_size=64, # typically you want as large of a batch size as you can fit in memory\n",
    "    hidden_layers=1, \n",
    "    hidden_layer_width=500,\n",
    "    optimizer='Adam', \n",
    "    early_stop=True, # prevents overfitting, highly recommended\n",
    "    early_stop_patience=0, # you can set what epoch you want to allow for early stopping\n",
    "    early_stop_method='accuracy',\n",
    "    manual_early_stop_epochs=None,\n",
    "    manual_early_stop_batch=None,\n",
    "    training_balance='category', \n",
    "    validation_balance='none', \n",
    "    trainable_layers=0, \n",
    "    l1=0, \n",
    "    l2=0, \n",
    "    l1_dense=None,\n",
    "    l2_dense=None, \n",
    "    dropout=0.2, \n",
    "    uq=False, # uncertainty quantification, adds much more time to training\n",
    "    augment='xyrjb', # all random augmentations: x=horizontal flip, y=vertical flip, r=rotate, j=jpeg compression, b=Gaussian blur, n=Stain Normalizer \n",
    "    normalizer=None, # 'reinhard_fast' is usually best\n",
    "    normalizer_source=None,\n",
    "    include_top=False, \n",
    "    drop_images=False)\n",
    "\n",
    "# 4. train model, will save in project models/ folder\n",
    "results = P.train(\n",
    "    outcomes=\"tumor_type\",\n",
    "    exp_label='test_tutorial', # this will become part of the name of the resulting trained model folder. Saved model name will be format \"00001-exp_label-outcome-epoch1\"\n",
    "    filters={\"dataset\": [\"train\"], \"exclude\": [\"no\"]},\n",
    "    pretrain='imagenet',\n",
    "    save_predictions=True, \n",
    "    params=hp,\n",
    "    # if doing k-fold cross validation\n",
    "    val_strategy='k-fold',\n",
    "    val_k_fold=3,\n",
    "    validate_on_batch=100 # this determines how often a validation step occurs. You can mess with this to get better early stopping results, depends on size of dataset\n",
    "    )\n",
    "\n",
    "# 5. evaluate model, will save in project eval/ folder\n",
    "P.evaluate(\n",
    "    model=\"/path/to/trained_model_epoch1\",\n",
    "    outcomes=\"tumor_type\",\n",
    "    filters={\"dataset\": [\"test\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have issues with downloading the Xception model during model initialization, you can add the following line to the beginning of the script to ignore the certificate to download the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can provide a dataset to the ```P.train()``` instead of using filters on the Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = P.dataset(tile_px=299, tile_um=302)\n",
    "dataset = dataset.filter({\"exclude\": [\"no\"]})\n",
    "\n",
    "# Option 1: use filters\n",
    "train_dataset = dataset.filter({\"dataset\": [\"train\"]})\n",
    "val_dataset = dataset.filter({\"dataset\": [\"val\"]})\n",
    "test_dataset = dataset.filter({\"dataset\": [\"test\"]})\n",
    "\n",
    "# Option 2: use split\n",
    "train_dataset, val_dataset, test_dataset = dataset.split(\n",
    "    train=0.8, val=0.1, test=0.1\n",
    ")\n",
    "\n",
    "# Train\n",
    "results = P.train(\n",
    "    outcomes=\"tumor_type\",\n",
    "    params=hp,\n",
    "    dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "P.evaluate(\n",
    "  model=\"/path/to/trained_model_epoch1\",\n",
    "  outcomes=\"tumor_type\",\n",
    "  dataset=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Training with a Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still bugs with this but we are working on it. Also this option is more complicated and not recommended for beginners but if you need to do more advanced things, you can use this option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dataset\n",
    "import os\n",
    "import slideflow as sf\n",
    "from pprint import pprint\n",
    "os.environ['SF_BACKEND'] = 'torch'\n",
    "tiles_savedir = '/home/pearsonlab/PROJECTS/CHRONIC_ENDOMETRITIS/data/cells/extracted_cells_tiles/'\n",
    "tfr_savedir = '/home/pearsonlab/PROJECTS/CHRONIC_ENDOMETRITIS/data/cells/extracted_cells_tfr/ALL/'\n",
    "tile_px = 96\n",
    "tile_um = '40x'\n",
    "tile_file_format = 'jpg'\n",
    "\n",
    "# Create a dataset\n",
    "dataset = sf.Dataset(\n",
    "    config='/home/pearsonlab/PROJECTS/CHRONIC_ENDOMETRITIS/data/cells/cell_classifier/datasets.json',\n",
    "    sources=['UCH_ENDOMETRITIS_EVAL_YOLO', 'UCH_ENDOMETRITIS_NEG_YOLO', 'UCH_ENDOMETRITIS_LOW_YOLO'],\n",
    "    annotations='/home/pearsonlab/PROJECTS/CHRONIC_ENDOMETRITIS/bennett_plasmacells_anns.csv',\n",
    "    # filters={'group': 'eval'}, # You can provide filters to the dataset or you can \n",
    "    tile_px=tile_px,\n",
    "    tile_um=tile_um,\n",
    ")\n",
    "dataset.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels\n",
    "labels, unique_labels = dataset.labels('cell_class')\n",
    "\n",
    "# prep dataset splits\n",
    "# NOTE I was splitting them randomly but that would split the patients up and I may get no negatives in my validation set and it was a problem\n",
    "(train_ds, val_ds) = dataset.filter({'group': 'train'}).split(model_type='categorical', labels='cell_class', val_strategy='fixed', val_fraction=0.3)\n",
    "train_ds = dataset.filter({'patient': ['NPC_Control_1', 'PC_Control_1', 'NPC_Control_2', 'PC_Control_2']})\n",
    "val_ds = dataset.filter({'patient': ['NPC_Control_3', 'PC_Control_3', 'NPC_Control_4', 'PC_Control_4']})\n",
    "test_ds = dataset.filter({'group': 'test'})\n",
    "eval_ds = dataset.filter({'slide': ['LowP1', 'LowP2', 'LowP3', 'LowP4']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import basename\n",
    "models_dir = '/home/pearsonlab/PROJECTS/CHRONIC_ENDOMETRITIS/data/cells/cell_classifier/models'\n",
    "eval_dir = '/home/pearsonlab/PROJECTS/CHRONIC_ENDOMETRITIS/data/cells/cell_classifier/eval'\n",
    "model_name = \"test_5e_bs64_vob40_uq\"\n",
    "exp_label = \"Lows\"\n",
    "outdir = f'{eval_dir}/eval-{model_name}-{exp_label}'\n",
    "model_path = '/home/pearsonlab/PROJECTS/CHRONIC_ENDOMETRITIS/data/cells/cell_classifier/models/test_5e_bs64_vob40_uq/test_5e_bs64_vob40_uq_epoch4'\n",
    "\n",
    "# read in params.json and edit to add in the info we need\n",
    "config = sf.util.get_model_config(model_path)\n",
    "config['outcomes'] = ['cell_class']\n",
    "config['outcome_labels'] = {\"0\": \"NPC\", \"1\": \"PC\"}\n",
    "config[\"input_features\"] = None\n",
    "config[\"input_feature_sizes\"] = None\n",
    "config[\"input_feature_labels\"] = None\n",
    "config[\"model_type\"] = \"categorical\"\n",
    "sf.util.write_json(config, os.path.join(model_path, 'params.json'))\n",
    "# also save in the higher directory\n",
    "sf.util.write_json(config, os.path.join('/home/pearsonlab/PROJECTS/CHRONIC_ENDOMETRITIS/data/cells/cell_classifier/models/test_5e_bs64_vob40_uq', 'params.json'))\n",
    "\n",
    "# Build trainer instead & then load model\n",
    "config = sf.util.get_model_config(model_path)\n",
    "hp = sf.ModelParams.from_dict(config['hp'])\n",
    "trainer = sf.model.Trainer(hp=hp,\n",
    "                 outdir=outdir,\n",
    "                 labels=labels,\n",
    "                 outcome_names=['cell_class'],\n",
    "                 name=f\"eval-{model_name}-{exp_label}\",\n",
    "                 config=config,\n",
    "                 load_method='weights',\n",
    "                 )\n",
    "trainer.load(model_path)\n",
    "\n",
    "# Evaluate\n",
    "results_dict = trainer.evaluate(eval_ds,\n",
    "                                batch_size=64,\n",
    "                                save_predictions='csv',\n",
    "                                uq=True,\n",
    "                                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
